{
 "cells": [
  {
   "cell_type": "raw",
   "id": "263be8a1",
   "metadata": {},
   "source": [
    "Design and implement a CNN for Image Classification a) Select a suitable image classification \n",
    "dataset (medical imaging, agricultural, etc.). b) Optimized with different hyper-parameters including \n",
    "learning rate, filter size, no. of layers, optimizers, dropouts, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08cf9002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense,Conv2D,Dropout,MaxPooling2D,Flatten\n",
    "from tensorflow.keras import models,Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e327843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(folder_path):\n",
    "    img_name = os.listdir(folder_path)\n",
    "    img = []\n",
    "    i = 0\n",
    "    for name in img_name:\n",
    "        if i < 100:\n",
    "            image = cv2.imread(os.path.join(folder_path,name))\n",
    "            img.append(image)\n",
    "            i+=1\n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b21e5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-08a29b18ba9b>:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return np.array(img)\n"
     ]
    }
   ],
   "source": [
    "train_t = load_img('C://Users//pajag//OneDrive//Desktop//img apple & tomato//train//tomatoes')\n",
    "train_a = load_img('C://Users//pajag//OneDrive//Desktop//img apple & tomato//train//apples')\n",
    "test_t = load_img('C://Users//pajag//OneDrive//Desktop//img apple & tomato//test//tomatoes')\n",
    "test_a = load_img('C://Users//pajag//OneDrive//Desktop//img apple & tomato//test//apples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf78a55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100,), (100,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_a.shape,train_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a7b32f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54,), (43,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_a.shape,test_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38287b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (64,64)\n",
    "def preprocess(arr):\n",
    "    resize = []\n",
    "    for img in arr:\n",
    "        img = cv2.resize(img,img_size)\n",
    "        img = img/255\n",
    "        resize.append(img)\n",
    "    return resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3688f0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a_preprocess = preprocess(train_a)\n",
    "train_t_preprocess = preprocess(train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2b961a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a_preprocess = preprocess(test_a)\n",
    "test_t_preprocess = preprocess(test_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3804768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1bf7008",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a_df = pd.DataFrame({'images':train_a_preprocess,'label':'0'})\n",
    "train_t_df = pd.DataFrame({'images':train_t_preprocess,'label':'1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fec67577",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_a_df = pd.DataFrame({'images':test_a_preprocess,'label':'0'})\n",
    "test_t_df = pd.DataFrame({'images':test_t_preprocess,'label':'1'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "818d39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.concat([train_a_df,train_t_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6318f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.concat([test_a_df,test_t_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90be9ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.iloc[np.random.permutation(len(data_train))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aaf83a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = data_test.iloc[np.random.permutation(len(data_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6658ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>[[[0.4588235294117647, 0.47058823529411764, 0....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>[[[0.08235294117647059, 0.22745098039215686, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>[[[0.9529411764705882, 0.9725490196078431, 0.9...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>[[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               images label\n",
       "92  [[[0.4588235294117647, 0.47058823529411764, 0....     1\n",
       "78  [[[0.08235294117647059, 0.22745098039215686, 0...     1\n",
       "13  [[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...     0\n",
       "56  [[[0.9529411764705882, 0.9725490196078431, 0.9...     0\n",
       "84  [[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...     0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b465739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[[[0.6392156862745098, 0.37254901960784315, 0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[[[1.0, 1.0, 1.0], [0.9607843137254902, 0.9607...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[[[0.5098039215686274, 0.6705882352941176, 0.7...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[[[0.24313725490196078, 0.40784313725490196, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               images label\n",
       "17  [[[0.6392156862745098, 0.37254901960784315, 0....     0\n",
       "25  [[[1.0, 1.0, 1.0], [0.9607843137254902, 0.9607...     0\n",
       "27  [[[0.5098039215686274, 0.6705882352941176, 0.7...     0\n",
       "16  [[[0.24313725490196078, 0.40784313725490196, 0...     1\n",
       "20  [[[1.0, 1.0, 1.0], [1.0, 1.0, 1.0], [1.0, 1.0,...     0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf9d0062",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_size[0], img_size[1], 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bce99566",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e59b76f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data_train['images']\n",
    "y = data_train['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b09f306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [tf.convert_to_tensor(img) for img in x]\n",
    "x = tf.stack(x)\n",
    "y = [tf.convert_to_tensor(val) for val in y]\n",
    "y = tf.strings.to_number(y,out_type=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cee7c37d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 [==============================] - 1s 231ms/step - loss: 0.7010 - accuracy: 0.5350\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 1s 223ms/step - loss: 0.7349 - accuracy: 0.5200\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 1s 228ms/step - loss: 0.6809 - accuracy: 0.5150\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 1s 226ms/step - loss: 0.6511 - accuracy: 0.6400\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 1s 220ms/step - loss: 0.6497 - accuracy: 0.6650\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 1s 223ms/step - loss: 0.6276 - accuracy: 0.6750\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 1s 222ms/step - loss: 0.5997 - accuracy: 0.6800\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 1s 214ms/step - loss: 0.5963 - accuracy: 0.6800\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 1s 221ms/step - loss: 0.5923 - accuracy: 0.7000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 1s 217ms/step - loss: 0.5616 - accuracy: 0.7250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2bef5f31c10>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x,y,batch_size=128,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba7fc2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data):\n",
    "    test_images = [tf.convert_to_tensor(images) for images in data['images'].values]\n",
    "    test_images = tf.stack(test_images)\n",
    "\n",
    "    test_labels = tf.convert_to_tensor(data['label'].values)\n",
    "    test_labels = tf.strings.to_number(test_labels, out_type=tf.float32)\n",
    "\n",
    "    loss, accuracy = model.evaluate(test_images, test_labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfcd8e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 21ms/step - loss: 0.5834 - accuracy: 0.6907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6907216310501099"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_model(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1872832b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(image_path):\n",
    "    # Load the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Check if the image was loaded successfully\n",
    "    if image is None:\n",
    "        print(f\"Failed to load image from path: {image_path}\")\n",
    "    else:\n",
    "        # Display the loaded image\n",
    "        cv2.imshow('Loaded Image', image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    return image\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
